\documentclass{article}
\usepackage[utf8]{inputenc}

\title{Label Smoothing with Graph Convolution}
\author{}
\date{}

\begin{document}

\maketitle

\section{Graph Convolution}



\newpage

\section{References}
\noindent {\bf Are Anchor Points Really Indispensable in Label-Noise Learning?}

\noindent NeurIPs 2019

\noindent Citations: 6

\begin{itemize}
    \item thiasdf a
\end{itemize}

\vspace{2cm}\noindent {\bf Combinatorial Inference against Label Noise}

\noindent NeurIPs 2019

\noindent Citations: None

\vspace{2cm}\noindent {\bf L\_DMI: A Novel Information-theoretic Loss Function for Training Deep Nets Robust to Label Noise}

\noindent NeurIPs 2019

\noindent Citations: None

\vspace{2cm}\noindent {\bf Robust Inference via Generative Classifiers for Handling Noisy Labels}

\noindent ICML 2019

\noindent Citations: None

\vspace{2cm}\noindent {\bf Unsupervised Label Noise Modeling and Loss Correction}

\noindent ICML 2019

\noindent Citations: None

\vspace{2cm}\noindent {\bf Learning to Learn from Noisy Labeled Data}

\noindent CVPR 2019

\noindent Citations: 26

\vspace{2cm}\noindent {\bf Co-teaching: Robust Training of Deep Neural Networks with Extremely Noisy Labels}

\noindent NeurIPs 2018

\noindent Citations: None

\vspace{2cm}\noindent {\bf Robustness of conditional GANs to noisy labels}

\noindent NeurIPs 2018

\noindent Citations: 17

\vspace{2cm}\noindent {\bf Masking: A New Perspective of Noisy Supervision}

\noindent NeurIPs 2018

\noindent Citations: None

\vspace{2cm}\noindent {\bf Using Trusted Data to Train Deep Networks on Labels Corrupted by Severe Noise}

\noindent NeurIPs 2018

\noindent Citations: None

\vspace{2cm}\noindent {\bf Generalized Cross Entropy Loss for Training Deep Neural Networks with Noisy Labels}

\noindent NeurIPs 2018

\noindent Citations: None

\vspace{2cm}\noindent {\bf Robot Learning in Homes: Improving Generalization and Reducing Dataset Bias}

\noindent NeurIPs 2018

\noindent Citations: None

\vspace{2cm}\noindent {\bf Learning to Reweight Examples for Robust Deep Learning}

\noindent ICML 2018

\noindent Citations: None

\vspace{2cm}\noindent {\bf Dimensionality-Driven Learning with Noisy Labels}

\noindent ICML 2018

\noindent Citations: None

\vspace{2cm}\noindent {\bf Exploring the Limits of Weakly Supervised Pretraining}

\noindent ICCV/ECCV 2018

\noindent Citations: None

\vspace{2cm}\noindent {\bf CurriculumNet: Weakly Supervised Learning from Large-Scale Web Images}

\noindent ICCV/ECCV 2018

\noindent Citations: None

\vspace{2cm}\noindent {\bf Deep Learning is Robust to Massive Label Noise (rejected from iclr 2018; referenced in iclr 2019 reject as "worth reading")}

\noindent ICLR 2018

\noindent Citations: None

\vspace{2cm}\noindent {\bf Joint Optimization Framework for Learning With Noisy Labels}

\noindent CVPR 2018

\noindent Citations: 96

\vspace{2cm}\noindent {\bf Iterative Learning With Open-Set Noisy Labels}

\noindent CVPR 2018

\noindent Citations: None

\vspace{2cm}\noindent {\bf CleanNet: Transfer Learning for Scalable Image Classifier Training With Label Noise}

\noindent CVPR 2018

\noindent Citations: None

\vspace{2cm}\noindent {\bf Detection and Correction of Mislabeled Training Samples for Hyperspectral Image Classification}

\noindent GRS 2018

\noindent Citations: None

\vspace{2cm}\noindent {\bf On the Resistance of Nearest Neighbor To Random Noisy Labels (reference by reviewer when rejecting iclr 2019 paper)}

\noindent ??? 2018

\noindent Citations: None

\vspace{2cm}\noindent {\bf Toward Robustness against Label Noise in Training Deep Discriminative Neural Networks}

\noindent NeurIPs 2017

\noindent Citations: 87

\vspace{2cm}\noindent {\bf Decoupling "when to update" from "how to update"}

\noindent NeurIPs 2017

\noindent Citations: 63

\vspace{2cm}\noindent {\bf Revisiting Unreasonable Effectiveness of Data in Deep Learning Era}

\noindent ICCV/ECCV 2017

\noindent Citations: 430

\vspace{2cm}\noindent {\bf Learning From Noisy Large-Scale Datasets With Minimal Supervision}

\noindent CVPR 2017

\noindent Citations: None

\vspace{2cm}\noindent {\bf Making Deep Neural Networks Robust to Label Noise: A Loss Correction Approach}

\noindent CVPR 2017

\noindent Citations: None

\vspace{2cm}\noindent {\bf Robust Loss Functions under Label Noise for Deep Neural Networks}

\noindent AAAI 2017

\noindent Citations: None

\vspace{2cm}\noindent {\bf Learning with Confident Examples: Rank Pruning for Robust Classification with Noisy Labels}

\noindent UAI 2017

\noindent Citations: None

\vspace{2cm}\noindent {\bf Effect of Training Class Label Noise on Classification Performances for Land Cover Mapping with Satellite Image Time Series}

\noindent MDPI 2017

\noindent Citations: None

\vspace{2cm}\noindent {\bf The Unreasonable Effectiveness of Noisy Data for Fine-Grained Recognition}

\noindent ICCV/ECCV 2016

\noindent Citations: 219

\vspace{2cm}\noindent {\bf Learning Visual Features from Large Weakly Supervised Data}

\noindent ICCV/ECCV 2016

\noindent Citations: 143

\vspace{2cm}\noindent {\bf Learning with Noisy Labels}

\noindent NeurIPs 2015

\noindent Citations: 483

\vspace{2cm}\noindent {\bf Learning with Symmetric Label Noise: The Importance of Being Unhinged}

\noindent NeurIPs 2015

\noindent Citations: 81

\vspace{2cm}\noindent {\bf Learning from massive noisy labeled data for image classification}

\noindent CVPR 2015

\noindent Citations: 322

\vspace{2cm}\noindent {\bf Learning discriminative reconstructions for unsupervised outlier removal.}

\noindent ICCV/ECCV 2015

\noindent Citations: 71

\vspace{2cm}\noindent {\bf classification with noisy labels by importance reweighting}

\noindent IPAM 2015

\noindent Citations: 327

\vspace{2cm}\noindent {\bf Training Deep Neural Networks on Noisy Labels with Bootstrapping}

\noindent ICLR 2014

\noindent Citations: 317

\vspace{2cm}\noindent {\bf A Modification on K-Nearest Neighbor Classifier}

\noindent GJCST 2010

\noindent Citations: None

\vspace{2cm}\noindent {\bf Learning with Local and Global Consistency}

\noindent NeurIPs 2004

\noindent Citations: 3769

\end{document}
